{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bb25af85-74d4-4a82-9716-27042ffaefca",
   "metadata": {},
   "source": [
    "# 第一章：GPU计算基础"
   ]
  },
  {
   "cell_type": "markdown", 
   "id": "d8b9556e-786c-4715-9913-62269bb2b872",
   "metadata": {},
   "source": [
    "## 引言\n",
    "\n",
    "图形处理器(GPU)是一种最初设计用于加速计算机图形和图像处理的专用电子电路。图形处理器具有专门的处理核心，可用于加速计算过程。\n",
    "\n",
    "虽然GPU最初是为处理图像和视觉数据而设计的，但现在它们被广泛应用于增强其他计算过程，如科学计算和机器学习。这是因为GPU可以有效地用于大规模分布式计算过程的并行处理。\n",
    "\n",
    "GPU编程领域非常广泛，理解GPU编程概念和Python GPU编程范式可能会让人望而生畏。在本指南中，我们希望能够揭开这个生态系统的神秘面纱，引导开发人员找到适合其特定加速计算需求的正确解决方案。\n",
    "\n",
    "![NVCube](images/chapter-01/cube.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce832813-05ab-411f-a315-fce51b254806", 
   "metadata": {},
   "source": [
    "### 并行计算模式\n",
    "\n",
    "GPU的主要优势在于并行性，即同时处理整体的各个部分。并行处理实现主要有四种架构，包括：\n",
    "- 单指令单数据流(SISD)\n", 
    "- 单指令多数据流(SIMD)\n",
    "- 多指令单数据流(MISD)\n",
    "- 多指令多数据流(MIMD)\n",
    "\n",
    "大多数CPU是多核处理器，采用MIMD架构运行。相比之下，GPU使用SIMD架构。这种差异使GPU特别适合需要对大量数据项执行相同处理的高度并行过程。\n"
   ]
  },
  {
    "cell_type": "markdown",
    "id": "c703f1c2-903b-4bbb-823a-ab6aafb7b0ef",
    "metadata": {},
    "source": [
     "### 通用GPU编程\n",
     "\n",
     "由于GPU最初的用途，这些处理器以前要求用户理解专门的语言，如OpenGL。这些语言仅用于GPU，使其难以学习并形成使用障碍。\n",
     "\n", 
     "2007年，随着NVIDIA CUDA框架的推出，这个障碍被打破，为更广泛地访问GPU资源提供了可能。CUDA基于C语言，并提供了一个API，开发人员可以使用它将GPU处理应用于其他任务。\n"
    ]
  },
  {
    "cell_type": "markdown",
    "id": "79dce745-0964-45f5-b188-1ba86b97c5ce",
    "metadata": {},
    "source": [
     "## CPU与GPU的优劣对比\n",
     "\n",
     "在构建程序在CPU或GPU上运行时，请记住这两种处理器的架构并不相同。指令不能在两个单元之间共享，它们也不会自动将工作从一个单元转移到另一个单元。程序员必须通过显式方式或通过使用支持GPU的软件包的隐式方式，有意识地在两者之间移动数据和处理。\n",
     "\n",
     "### CPU\n",
     "\n",
     "中央处理器(CPU)是当今计算机中最常见的处理器类型，长期以来一直是数据分析任务的主力。CPU由多个可以顺序和并行执行指令的核心组成，使其适用于广泛的应用。\n",
     "\n",
     "#### CPU优势      \n",
     "\n",
     "CPU具有以下几个优势：\n",
     "- 通用性：CPU可以处理各种通用任务，如逻辑比较、寄存器间数据传输和文件管理。CPU在处理RAM中的数据处理、I/O操作和操作系统管理等操作时比GPU更快。\n",
     "- 多任务处理：CPU可以同时运行多个任务。\n",
     "- 高时钟速度：CPU通常具有比GPU更高的时钟速度，这使它们能够更快地执行单线程任务。\n",
     "- 灵活性：CPU可以在多个活动之间进行多任务处理，并快速切换上下文。\n",
     "- 缓存内存：CPU具有大容量的本地缓存内存。\n",
     "- 兼容性：CPU与所有类型的系统兼容，而GPU可能需要专门的硬件。\n",
     "\n",
     "#### CPU劣势\n",
     "\n",
     "尽管有这些优势，CPU仍有一些限制：\n",
     "- 有限的并行处理：CPU不是为高度并行工作负载设计的。\n",
     "- 高功耗：CPU可能消耗大量电力，这可能会增加运营成本。\n",
     "- 内存带宽限制：与GPU相比，CPU的内存带宽有限，在处理大型数据集时可能会导致性能较慢。\n",
     "- 并行处理：CPU不擅长需要执行数百万个相同操作的任务。\n",
     "- 发展限制：CPU是一项非常成熟的技术，改进潜力较小，而GPU仍有较大发展空间。\n",
     "\n",
     "总的来说，CPU是许多任务的通用可靠选择，但对于计算密集型、高度并行的工作负载或在时间和预算限制下的大规模操作可能不是最佳选择。\n",
     "\n",
     "### GPU\n",
     "\n",
     "图形处理器(GPU)最初是为渲染图形和图像而设计的，但近年来已成为其他通用计算任务的强大加速器。GPU由数千个可以并行执行指令的处理核心组成，使其非常适合计算密集型任务。\n",
     "\n",
     "#### GPU优势\n",
     "\n",
     "GPU具有以下几个优势：\n",
     "- 并行处理：GPU可以同时对多个数据点并行处理数千个计算。GPU具有数百个核心，允许进行大规模并行计算，如矩阵乘法。\n",
     "- 高内存带宽：GPU可以更快地访问和操作数据。\n",
     "- 能源效率：GPU可能比CPU消耗更少的电力，从而降低运营成本。\n",
     "- 可定制架构：GPU可以针对特定应用和工作负载进行定制，使其灵活且适应性强。\n",
     "- 科学计算用例：GPU为生成式AI、深度学习和大数据操作等专业任务提供大规模加速。\n",
     "\n",
     "#### GPU劣势\n",
     "\n",
     "尽管有这些优势，GPU仍有一些限制，包括：\n",
     "- 多任务处理限制：GPU可以在大规模重复执行一个任务，但无法像CPU那样执行通用计算任务。\n",
     "- 复杂性：GPU在处理分支逻辑、顺序操作或其他复杂编程模式时表现欠佳。\n",
     "- 软件兼容性：GPU可能需要额外的编程或优化才能有效工作。\n",
     "\n",
     "总的来说，GPU是需要高性能和并行处理的任务的强大高效选择。这使它们特别适合加速倾向于对大量数据执行重复操作的科学Python代码。"
    ]
  },
  {
    "cell_type": "markdown",
    "id": "77da5fb1-d6d2-494f-856e-c5cda4c66cb7",
    "metadata": {},
    "source": [
     "## GPU架构\n",
     "\n",
     "为了理解如何最大限度地利用GPU，我们需要了解GPU架构的基础知识。为了简单起见，我们可以将单个GPU设备视为由多个流式多处理器集群组成。\n",
     "\n",
     "_GPU架构的简化视图_\n",
     "\n",
     "![GPUArch](images/chapter-01/gpu-arch.png)\n"
    ]
  },
  {
    "cell_type": "markdown",
    "id": "c48ad9bd-a645-4ab0-9d79-bd03bf79a749",
    "metadata": {},
    "source": [
     "单个GPU设备由多个处理器集群(PC)组成，每个集群包含多个流式多处理器(SM)。每个SM都包含一个一级指令缓存层及其相关核心。通常，一个SM使用专用的一级缓存和共享的二级缓存，然后从全局GDDR-5（或较新GPU型号中的GDDR-6）内存中提取数据。其架构对内存延迟具有较强的容忍度。\n",
     "\n",
     "与CPU相比，由于有更多晶体管专用于计算，GPU的内存缓存层较少且相对较小。GPU不太关心从内存检索数据需要多���时间，只要这种内存访问"延迟"能被大规模并行计算所掩盖。\n",
     "\n",
     "GPU针对数据并行吞吐量计算进行了优化。查看核心数量就能快速了解它能够实现的并行性可能性。\n",
     "\n",
     "这就是GPU编程的力量。如果我们能够在优化数据传输的同时利用大量核心，我们就能大大加速我们的应用程序。"
    ]
  },
  {
    "cell_type": "markdown",
    "id": "b89b9f26-b885-4ed4-bf9a-d53b2635f1d2",
    "metadata": {},
    "source": [
     "## NVIDIA GPU的演进\n",
     "有多种选择，您可以选择消费级GPU、数据中心GPU和托管工作站。\n",
     "\n",
     "![GPUHW](images/chapter-01/gpu-hw.png)\n",
     "\n",
     "### 消费级GPU\n",
     "\n",
     "消费级GPU不适合大规模深度学习项目，但可以作为实施的入门点。这些GPU使您能够以低成本补充现有系统，对于模型构建或低级测试很有用。\n",
     "\n",
     "有关NVIDIA GeForce显卡的最新信息，请访问：https://www.nvidia.com/en-us/geforce/graphics-cards/ \n",
     "\n",
     "### 数据中心GPU\n",
     "\n",
     "数据中心GPU是生产级深度学习实施的标准。这些GPU专为大规模项目设计，可提供企业级性能。\n",
     "\n",
     "有关NVIDIA数据中心解决方案的最新信息，请访问：https://www.nvidia.com/en-us/data-center/data-center-gpus/ \n",
     "\n",
     "### DGX服务器\n",
     "\n",
     "NVIDIA DGX服务器是企业级的全栈解决方案。这些系统专门为机器学习和深度学习操作而设计。系统即插即用，您可以在裸机服务器上或在容器中部署。\n",
     "\n",
     "有关NVIDIA DGX服务器的最新信息，请访问：https://www.nvidia.com/en-us/data-center/dgx-platform/ "
    ]
  },
  {
    "cell_type": "markdown",
    "id": "06307091-2cf2-4f4c-9d62-78fabbe7d66e",
    "metadata": {},
    "source": [
     "## 常见的GPU加速应用\n",
     "\n",
     "GPU常用于以下任务：\n",
     "- 科学模拟和建模\n",
     "- 机器学习和神经网络\n",
     "- 深度学习\n",
     "\n",
     "### 科学计算\n",
     "\n",
     "GPU可以与CPU配合使用，快速执行数值密集型操作，如科学模拟和建模。GPU设计传统上注重最大化浮点运算单元和执行多维数组运算。它们特别适合线性数学或矩阵运算有用的应用。这得益于GPU的TensorCore单元，可优化矩阵乘法运算。\n",
     "\n",
     "GPU实现存在于许多科学计算问题中，包括分子建模、流体动力学、天体物理学和气候模拟。\n",
     "\n",
     "### 深度学习\n",
     "\n",
     "神经网络通过学习海量数据来模拟人脑的行为。在训练阶段，神经网络扫描输入数据并与标准数据进行比较，以便形成预测和预报。\n",
     "\n",
     "由于神经网络主要处理海量数据集，随着数据集的增长，训练时间可能会增加。虽然使用CPU可以训练较小规模的神经网络，但CPU在处理这些大量数据时效率较低，导致添加更多层和参数时训练时间增加。\n",
     "\n",
     "神经网络构成了深度学习（具有三层或更多层的神经网络）的基础，并设计为并行运行，每个任务独立于其他任务运行。这使得GPU更适合处理用于训练神经网络的庞大数据集和复杂数学数据。\n",
     "\n",
     "### 大规模并行输入的深度学习\n",
     "\n",
     "NVIDIA推出CUDA后，开发了几个深度学习框架，如PyTorch和TensorFlow。这些框架抽象了直接使用CUDA编程的复杂性，使GPU处理对现代深度学习实现变得容易访问。\n",
     "\n",
     "深度学习模型是具有三层或更多层的神经网络。深度学习模型具有高度灵活的架构，允许它们直接从原始数据中学习。使用大型数据集训练深度学习网络可以提高其预测准确性。\n",
     "\n",
     "CPU对深度学习的效率低于GPU，因为它们按顺序一次处理一个任务。随着用于输入和预测的数据点增加，CPU越来越难以管理所有相关任务。\n",
     "\n",
     "深度学习需要很高的速度和性能，当所有操作同时处理时，模型学习得更快。由于GPU具有数千个核心，它们针对训练深度学习模型进行了优化，可以比CPU快三倍处理多个并行任务。"
    ]
  },
  {
    "cell_type": "markdown",
    "id": "6a92e525-0391-4add-8dba-aaf2e52f920f",
    "metadata": {},
    "source": [
     "## 资源\n",
     "\n",
     "NVIDIA GPU架构：https://www.nvidia.com/en-us/technologies/ \n",
     "\n",
     "NVIDIA CUDA支持的处理器：https://developer.nvidia.com/cuda-gpus \n",
     "\n",
     "NVIDIA加速应用程序目录：https://www.nvidia.com/en-us/accelerated-applications/ \n",
     "\n",
     "NVIDIA GPU云应用程序目录：https://catalog.ngc.nvidia.com/ "
    ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
} 