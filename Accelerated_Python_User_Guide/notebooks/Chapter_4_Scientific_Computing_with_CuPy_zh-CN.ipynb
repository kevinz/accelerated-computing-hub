{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0d57565e-f93f-4878-bebc-deb6ca2fc195",
   "metadata": {},
   "source": [
    "# 第 4 章：使用 CuPy 进行科学计算\n",
    "\n",
    "<img src=\"images/chapter-04/cupy_title.png\" style=\"width:600px;\"/>\n",
    "\n",
    "CuPy 是一个与 NumPy 和 SciPy 兼容的数组库，用于使用 Python 进行 GPU 加速计算。CuPy 可作为在 NVIDIA CUDA 或 AMD ROCm 平台上运行现有 NumPy 和 SciPy 代码的替代品。\n",
    "\n",
    "CuPy 是 Chainer 项目的一部分，但其维护者来自包括 NVIDIA 在内的许多组织。CuPy 实现了熟悉的 Numpy API，但后端是用 CUDA C++ 编写的。这使得已经熟悉 Numpy 的人只需切换导入即可快速获得 GPU 加速。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37f30728-3612-4d9f-a3d8-5b0053759f24",
   "metadata": {},
   "source": [
    "## CuPy 基础知识\n",
    "\n",
    "CuPy 是一个与 NumPy/SciPy 兼容的数组库，用于 GPU 加速计算。CuPy 可作为 NumPy/SciPy 代码的替代品在 NVIDIA CUDA 或 AMD ROCm 平台上运行。\n",
    "\n",
    "CuPy 提供了多维数组、稀疏矩阵以及相关的例程，适用于 GPU 设备，都具有与 NumPy 和 SciPy 相同的 API。\n",
    "\n",
    "CuPy项目的目标是为Python用户提供GPU加速能力，无需深入了解底层 GPU 技术。CuPy 团队专注于提供：\n",
    "- 完整的 NumPy 和 SciPy API 覆盖，成为完整的替代品，以及先进的 CUDA 功能来最大限度地提高性能。\n",
    "- 成熟和高质量的库作为所有需要加速的项目的基础包，从实验室环境到大规模集群。\n",
    "\n",
    "### N 维数组/ Cupy.ndarray 数据结构\n",
    "\n",
    "`cupy.ndarray` 是 NumPy `numpy.ndarray` 的 CuPy 对应项。它提供固定大小多维数组的直观界面，位于 CUDA 设备上。\n",
    "\n",
    "此类实现了 numpy.ndarray 的子集方法。不同之处在于此类在当前GPU设备上分配数组内容。\n",
    "\n",
    "### 内存管理\n",
    "\n",
    "CuPy 默认使用内存池进行内存分配。内存池通过减少内存分配的开销来显著提高性能以及 CPU/GPU 同步。\n",
    "\n",
    "CuPy 中有两个不同的内存池：\n",
    "- 设备（GPU）内存池 - 用于 GPU 内存分配。\n",
    "- 固定（CPU）内存池 - CPU 到 GPU 数据传输期间使用的不可交换内存。\n",
    "\n",
    "在大多数情况下，CuPy 用户不需要了解内存分配的具体细节和释放，但重要的是要理解这种优化来对应用程序的性能进行基准测试。您可能看不到内存由于内存池中的缓存而被完全释放。\n",
    "\n",
    "CuPy 既提供了控制此内存的高级 API，也提供了 CUDA 内存管理功能的低级 API。\n",
    "\n",
    "### 当前设备\n",
    "\n",
    "CuPy 有一个当前设备的概念，它是数组的分配、操作、计算等都发生在其上的默认 GPU 设备（默认 id=0）。所有 CuPy 操作（多 GPU 功能和设备到设备复制除外）都在当前活动设备上执行。\n",
    "\n",
    "通常，CuPy 函数要求数组与当前设备位于同一设备上。传递存储在非当前设备上的数组可能会起作用，具体取决于硬件配置，但通常不建议这样做，因为这样做可能性能不佳。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6feb576-fb49-487d-b518-f61c3c6dd2cf",
   "metadata": {},
   "source": [
    "## API 接口\n",
    "\n",
    "### Cupy.ndarray\n",
    "\n",
    ""cupy.ndarrays"是 CuPy 生态系统的支柱，提供了"numpy.ndarrays"的直观对应物。"cupy.ndarrays"与"numpy.ndarrays"一样，是相同类型和大小的项目的固定大小的多维容器。\n",
    "\n",
    "### Cupy.ufuncs\n",
    "\n",
    "在 NumPy 中，通用函数（简称 ufunc）被定义为以逐个元素的方式对 ndarray 进行操作的函数，支持数组广播、类型转换和其他几个标准功能。换句话说，ufunc 是一个函数的"矢量化"包装器，它接受固定数量的特定输入并产生固定数量的特定输出。这些函数主要对 NumPy 数组进行操作，是加速 Python 代码的最有效方法之一。（请参阅 NumPy 通用函数：https://numpy.org/doc/stable/reference/ufuncs.html）\n",
    "\n",
    "类似地，CuPy 实现了类似的 ufunc，也支持广播、类型转换和输出类型确定。用户可以定义 `cupy.ufuncs`，在 `cupy.ndarray` 对象上模仿 NumPy ufuncs。\n",
    "\n",
    "### NumPy 和 SciPy 覆盖范围\n",
    "\n",
    "可用的 NumPy 例程：https://docs.cupy.dev/en/stable/reference/routines.html\n",
    "可用的 SciPy 例程：https://docs.cupy.dev/en/stable/reference/scipy.html\n",
    "\n",
    "虽然 CuPy 的设计模仿了 NumPy，但使用 CuPy 也存在一些限制：\n",
    "- 并非所有 NumPy 和 SciPy 函数都与 CuPy 兼容。\n",
    "- CuPy 可能并不总是能提供显著的性能改进。\n",
    "- 性能高度依赖于执行的操作和所使用的硬件。\n",
    "\n",
    "CuPy 和 NumPy 之间也存在一些差异，可能需要对代码进行调整：\n",
    "- 从浮点数到整数的转换行为可能与硬件有关。这是 C++ 中类型转换限制的结果。\n",
    "- 随机函数差异。NumPy `random()` 函数不支持 `dtype` 参数，但 CuPy 内部的随机数生成器 cuRAND 却支持该参数。\n",
    "- 使用整数数组索引时，CuPy 默认处理越界索引的方式与 NumPy 不同。NumPy 通过引发错误来处理它们，但 CuPy 会绕过它们。\n",
    "- 矩阵类型（`numpy.matrix`） - 当从稀疏矩阵计算密集矩阵（例如`coo_matrix + ndarray`）时，SciPy 返回`numpy.matrix`（`numpy.ndarray` 的子类）。但是，对于此类操作，CuPy 返回`cupy.ndarray`。\n",
    "- CuPy 数组不能是非数字的，如字符串或对象。\n",
    "- CuPy 中的通用函数仅适用于 CuPy 数组或标量。它们不接受其他对象（例如列表或"numpy.ndarray"）。\n",
    "- 与 Numpy 一样，CuPy 的 RandomState 对象接受数字或完整的 numpy 数组作为种子。\n",
    "- NumPy 的归约函数（例如"numpy.sum()"）返回标量值（例如"numpy.float32"）。然而，CuPy 对应物返回零维"cupy.ndarrays"。\n",
    "\n",
    "还有更多差异，但这些是最常见的。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "404aafdc-1e3c-4707-b0d7-f67873f2b049",
   "metadata": {},
   "source": [
    "## 编码指南\n",
    "\n",
    "### 安装\n",
    "\n",
    "在设置 CuPy 编程环境之前，首先确保您已满足以下先决条件：\n",
    "- 兼容 CUDA 的 GPU。（请参阅 https://developer.nvidia.com/cuda-gpus 查看 NVIDIA GPU 列表）\n",
    "- 与 CUDA 兼容的 NVIDIA 驱动程序。\n",
    "- CUDA 工具包\n",
    "\n",
    "您的 CUDA 工具包版本将决定您需要安装的 NVIDIA 驱动程序版本。CUDA 工具包与许多操作系统兼容，包括 Windows、Linux 和 macOS，但您可能需要根据您打算使用的 CUDA 工具包版本更新操作系统版本。\n",
    "\n",
    "请参阅当前安装说明：https://docs.cupy.dev/en/stable/install.html\n",
    "\n",
    "### 最佳实践\n",
    "\n",
    "在将程序转换为 CuPy 之前，请务必使用 NumPy 和 SciPy 优化其在 CPU 上的实现。对初始实现进行基准测试将有助于您确定在转移到 GPU 时是否正在加速程序。\n",
    "\n",
    "要将处理从 NumPy 转移到 CuPy，您需要：\n",
    "- 导入 CuPy。\n",
    "- 将 NumPy 中的所有调用移至 CuPy。\n",
    "- CuPy 涵盖了大部分 NumPy API，因此请先尝试一下。\n",
    "- 将 NumPy ndarray 移动到 CuPy ndarray\n",
    "- 使用"cupy.array()"或"cupy.asarray()"\n",
    "- 在 GPU 处理后将 CuPy ndarrays 转换回 NumPy ndarrays\n",
    "- 使用 `cupy.asnumpy()` 或 `cupy.ndarray.get()`\n",
    "\n",
    "例如，这个 NumPy 调用：\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "x_cpu = np.ones((1000,500,500))\n",
    "```\n",
    "\n",
    "对应于此 CuPy 调用：\n",
    "```python\n",
    "import cupy as cp\n",
    "x_gpu = cp.ones((1000,500,500))\n",
    "x_cpu = cp.asnumpy(x_gpu)\n",
    "```\n",
    "\n",
    "如果您正在对代码进行基准测试，则需要明确调用 `cp.cuda.Stream.null.synchronize()` 以确保时间公平。默认情况下，CuPy 将同时运行 GPU 代码，并且该函数将在 GPU 完成之前退出。调用 `synchronize()` 会让我们等待 GPU 完成后再返回。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a88e1c7-85de-4a9a-aa6c-47242c5c4e36",
   "metadata": {},
   "source": [
    "### 超越 NumPy 和 SciPy\n",
    "\n",
    "不幸的是，NumPy 和 SciPy 不一定能提供开发软件所需的所有功能。在这种情况下，你需要了解 CuPy 中的一些重要模式：\n",
    "\n",
    "#### CuPy 内核编译\n",
    "\n",
    "CuPy 提供三个内核编译类。该类的实例定义了一个 CUDA 内核，可以通过该实例的 `__call__` 方法调用：\n",
    "- ElementwiseKernel - 像 for 循环一样对数组的每个元素执行。\n",
    "- ReductionKernel - 执行 map、reduce 和 post-reduce 函数。\n",
    "- RawKernel - 使用原始 CUDA 源代码定义内核，并控制网格大小、块大小等。\n",
    "\n",
    "这些类型中的每一种也可以使用 `@cupyx.jit.*` 装饰器对应部分来定义：`@cupyx.jit.elementwisekernel`、`@cupyx.jit.reductionkernel` 和 `@cupy.jit.rawkernel`。\n",
    "\n",
    "#### CuPy 类型通用内核\n",
    "\n",
    "如果内核函数中的类型信息用一个字符定义，则该字符将被视为类型占位符。整个函数中重复出现的相同字符将被推断为相同类型。这允许创建可重复使用的通用内核。\n",
    "\n",
    "#### 在 GPU 设备之间移动\n",
    "\n",
    "如果您需要在 GPU 之间移动数据（从设备到另一设备），请使用 with 语句创建上下文。如果您出于能耗或性能方面的考虑，想要在系统中的集成显卡和专用显卡之间切换，您可能需要这样做。\n",
    "\n",
    "```python\n",
    "import cupy as cp\n",
    "\n",
    "device_id = 1\n",
    "\n",
    "#Create context for device 1\n",
    "with cp.cuda.Device(device_id):\n",
    "   array_on_device1 = cp.array([1, 2, 3, 4, 5])\n",
    "\n",
    "#Out of scope for context and execute on device 0\n",
    "array_on_device0 = cp.array([1, 2, 3, 4, 5]) \n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2c0f428-3010-43c4-9600-29a480ddde24",
   "metadata": {},
   "source": [
    "## 性能考虑\n",
    "\n",
    "### 将数据从 CPU 移动到 GPU\n",
    "\n",
    "为了充分利用 GPU，我们需要通过主板上的 PCI 总线将数据移动到 GPU。这意味着我们需要将数据和代码移动到设备并执行该代码。这样，CPU 和 GPU 之间的 PCI 总线可能会成为瓶颈。\n",
    "\n",
    "将数据从 CPU 移动到 GPU 或反之亦然会产生一次性性能成本。\n",
    "\n",
    "### 分支\n",
    "\n",
    "具有许多逻辑分支的程序需要 CPU。在 CPU 和 GPU 之间切换会产生成本，这可能会影响性能。具有大量 if-then 语句的程序可能更适合 CPU，具体取决于在两个处理器之间切换的开销。\n",
    "\n",
    "确保您的函数是矢量化的，以尽量减少分支。\n",
    "\n",
    "### 编译内核函数\n",
    "\n",
    "当需要内核调用时，CuPy 会编译针对给定参数的维度和数据类型优化的内核代码，将其发送到 GPU 设备并执行该内核。然后，CuPy 会在进程内缓存发送到 GPU 设备的内核代码，从而减少后续调用的内核编译时间。\n",
    "\n",
    "编译内核函数会产生一次性的性能成本。\n",
    "\n",
    "### 从当前设备移动数据\n",
    "\n",
    "通常，CuPy 函数要求数组与当前设备位于同一设备上。与将数据从 CPU 传递到 GPU 或反之亦然类似，传递存储在非当前设备上的数组可能会对性能产生负面影响，具体取决于硬件配置。\n",
    "\n",
    "当数据从一个设备移动到另一个设备时，性能会受到影响。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "267ada4e-10a5-4bf1-9935-ba085dc77028",
   "metadata": {},
   "source": [
    "## 方便参考的链接\n",
    "\n",
    "有关更多信息，请参阅 CuPy 用户指南：https://docs.cupy.dev/en/stable/user_guide/index.html\n",
    "\n",
    "CuPy API 参考：https://docs.cupy.dev/en/stable/reference/index.html\n",
    "\n",
    "CuPy Github 存储库（包含更多示例）：https://github.com/cupy/cupy\n",
    "\n",
    "NumPy 用户指南：https://numpy.org/doc/stable/user/\n",
    "\n",
    "NumPy API 指南：https://numpy.org/doc/stable/reference/index.html\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93b74393-0393-4d24-be0e-d510b4f23c02",
   "metadata": {},
   "source": [
    "# 示例"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77d290b7-c8de-4b8b-b3f0-6a8ea1c9dd16",
   "metadata": {},
   "source": [
    "## 从 NumPy 到 CuPy 的简单转换"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2393610-8392-4d66-b86b-3c5abc6b2447",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "x_cpu = np.ones((1000,500,500))\n",
    "\n",
    "x_cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b8965c4-ea45-4c68-9c35-b076fa7656dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cupy as cp\n",
    "x_gpu = cp.ones((1000,500,500))\n",
    "x_cpu = cp.asnumpy(x_gpu)\n",
    "\n",
    "x_cpu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b16fd541-ab9d-43fa-9810-9e5e50981e3b",
   "metadata": {},
   "source": [
    "## 从 NumPy 到 CuPy 的更复杂转换"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0b73208-a9f9-4a2e-b76d-c811bfc56c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "x_cpu = np.random.random((1000, 1000))\n",
    "x_cpu *= 2 \n",
    "u, s, v = np.linalg.svd(x_cpu)\n",
    "\n",
    "u, s, v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9818a469-a984-4cd9-9ebb-2617fe141f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cupy as cp\n",
    "\n",
    "x_gpu = cp.random.random((1000, 1000))\n",
    "x_gpu *= 2 \n",
    "u, s, v = cp.linalg.svd(x_gpu)\n",
    "\n",
    "u, s, v"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d99830d2-e277-4de2-b10d-88a044250d0e",
   "metadata": {},
   "source": [
    "## 添加用户定义的核函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e90030b7-da4c-44b3-897d-cdfa9828e2d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cupy\n",
    "from cupyx import jit\n",
    "\n",
    "\n",
    "@jit.rawkernel()\n",
    "def elementwise_copy(x, y, size):\n",
    "    tid = jit.blockIdx.x * jit.blockDim.x + jit.threadIdx.x\n",
    "    ntid = jit.gridDim.x * jit.blockDim.x\n",
    "    for i in range(tid, size, ntid):\n",
    "        y[i] = x[i]\n",
    "\n",
    "\n",
    "size = cupy.uint32(2 ** 22)\n",
    "x = cupy.random.normal(size=(size,), dtype=cupy.float32)\n",
    "y = cupy.empty((size,), dtype=cupy.float32)\n",
    "\n",
    "elementwise_copy((128,), (1024,), (x, y, size))\n",
    "\n",
    "elementwise_copy[128, 1024](x, y, size)\n",
    "\n",
    "assert (x == y).all()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
} 