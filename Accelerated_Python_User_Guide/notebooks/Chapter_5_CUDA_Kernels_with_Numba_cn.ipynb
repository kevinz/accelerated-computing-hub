{
    "cells": [
     {
      "attachments": {},
      "cell_type": "markdown",
      "id": "fab639be-7012-4227-8179-077ce5e40816",
      "metadata": {},
      "source": [
       "# 第5章：使用Numba编写CUDA内核\n",
       "\n",
       "<img src=\"images/chapter-05/numba_title.png\" style=\"width:442px;\"/>\n",
       "\n",
       "Numba是一个开源的JIT编译器,可以将Python和NumPy代码的子集转换为快速的机器代码。\n",
       "\n",
       "Numba通过直接将受限的Python代码子集编译成CUDA内核和设备函数来支持CUDA GPU编程,遵循CUDA执行模型。用Numba编写的内核可以直接访问NumPy数组。NumPy数组在CPU和GPU之间自动传输。\n"
      ]
     },
     {
      "cell_type": "markdown",
      "id": "ef00a9d1-46df-4e79-bf44-a40944144cff",
      "metadata": {},
      "source": [
       "## Numba基础\n",
       "\n",
       "Numba通过直接将受限的Python代码子集编译成CUDA内核和设备函数来支持CUDA GPU编程,遵循CUDA执行模型。用Numba编写的内核可以直接访问NumPy数组。NumPy数组在CPU和GPU之间自动传输。Numba的集成编译系统允许使用CPU和GPU的特性创建代码,而不需要对Python语言进行太多更改。\n",
       "\n",
       "### 安装\n",
       "\n",
       "在设置Numba编程环境之前,首先确保您满足以下先决条件(如果您按照安装CuPy的说明操作,可以跳过这些步骤)：\n",
       "- CUDA兼容的GPU。(参见https://developer.nvidia.com/cuda-gpus 获取NVIDIA GPU列表)\n",
       "- CUDA兼容的NVIDIA驱动程序。\n",
       "- CUDA工具包\n",
       "\n",
       "查看安装说明：https://numba.pydata.org/numba-doc/latest/user/installing.html \n",
       "\n",
       "### 使用`@cuda.jit`创建内核函数\n",
       "\n",
       "在Numba中,`@jit`装饰器用于指定要由Numba即时编译器优化的函数。在GPU的上下文中,我们使用名为`@cuda.jit`的版本来指定要由GPU上的多个线程同时执行的内核函数进行优化。\n",
       "\n",
       "```python\n",
       "from numba import cuda\n",
       "\n",
       "@cuda.jit\n",
       "def foo(input_array, output_array):\n",
       "    # 代码块在这里\n",
       "\n",
       "这应该看起来与在CPU上使用numba非常相似。\n"
      ]
     },
     {
      "cell_type": "markdown",
      "id": "083129b4-dd95-47e3-b3e5-0113e6f47b01",
      "metadata": {},
      "source": [
       "### 启动内核函数\n",
       "\n",
       "在运行内核函数之前,需要指定块数和每个块的线程数。这将定义执行网格的形状。\n",
       "\n",
       "```python\n",
       "@cuda.jit\n",
       "def foo(input_array, output_array):\n",
       "    # 1D块中的线程ID\n",
       "    thread_id = cuda.threadIdx.x\n",
       "    # 1D网格中的块ID\n",
       "    block_id = cuda.blockIdx.x\n",
       "    # 块宽度,即每个块的线程数\n",
       "    block_width = cuda.blockDim.x\n",
       "    # 计算数组内的扁平化索引\n",
       "    i = thread_id + block_id * block_width\n",
       "    if i < an_array.size:  # 检查数组边界\n",
       "        output_array[i] = input_array[i]\n",
       "```\n",
       "\n",
       "要调用`foo()`函数,我们必须指定块和网格大小。\n",
       "\n",
       "```python\n",
       "input = np.asarray(range(10))\n",
       "output = np.zeros(len(input))\n",
       "\n",
       "\n",
       "block_threads = 32\n",
       "grid_blocks = (input.size + (block_threads - 1)) // block_threads\n",
       "\n",
       "foo[grid_blocks, block_threads](input, output)\n",
       "```\n",
       "\n",
       "对于简单的示例,`cuda.grid()`函数是管理线程、块和网格的便捷方式。完整的脚本可以这样重写：\n",
       "\n",
       "```python\n",
       "import numpy as np\n",
       "from numba import cuda\n",
       "\n",
       "input = np.asarray(range(10))\n",
       "output = np.zeros(len(input))\n",
       "\n",
       "@cuda.jit\n",
       "def foo(input_array, output_array):\n",
       "    i = cuda.grid(1)\n",
       "    output_array[i] = input_array[i]\n",
       "    \n",
       "foo[1, len(input)](input, output)\n",
       "\n",
       "output\n",
       "```\n",
       "\n",
       "注意：当CUDA内核执行时,调用会在GPU完成之前立即返回。然后需要同步内核执行,以确保结果被传回CPU。如果不完成此步骤,您可能会遇到内存错误,因为后续调用试图读取或写入受限内存。使用cuda.synchronize()确保数据一致性。\n"
      ]
     },
     {
      "cell_type": "markdown",
      "id": "a4de366c-b222-498e-861a-36acc997c9d7",
      "metadata": {},
      "source": [
       "### 指定线程数和块数\n",
       "\n",
       "现在不要太担心这个。只需记住我们需要指定要调用内核的次数,这是通过两个相乘得到总网格大小的数字给出的。这种设置将确保网格大小有足够的线程来处理数据大小,即使该数字不是每个块的线程数的精确倍数。\n",
       "\n",
       "每个块的线程数经验法则：\n",
       "- 最佳块大小通常是32(warp大小)的倍数。\n",
       "- 需要分析和基准测试来确定最佳值。\n",
       "\n",
       "入门：\n",
       "- NSight的占用率计算器：https://docs.nvidia.com/nsight-compute/NsightCompute/index.html#occupancy-calculator)\n",
       "- 多个来源建议从128到256之间的数字开始调优。\n",
       "\n",
       "块和网格维度会影响CUDA性能。较大的块可以导致更好地利用共享内存并减少启动许多小块的开销。但是,过大的块可能会减少可以并发执行的块数量,这将导致GPU利用率不足。找到正确的平衡对于利用GPU是必要的。\n"
      ]
     },
     {
      "cell_type": "markdown",
      "id": "73d5185d-1507-44dd-8930-dd3c33a908bd",
      "metadata": {},
      "source": [
       "## Numba与CuPy\n",
       "\n",
       "CuPy的`cupy.ndarray`实现了`__cuda_array_interface__`,这是与Numba v0.39.0或更高版本兼容的CUDA数组交换接口(详见Numba的CUDA数组接口 https://numba.readthedocs.io/en/stable/cuda/cuda_array_interface.html)。这意味着您可以将CuPy数组传递给用Numba JIT编译的内核。\n",
       "\n",
       "在此示例中,我们使用`cupy`数组而不是`numpy`数组：\n",
       "\n",
       "```python\n",
       "import cupy\n",
       "from numba import cuda\n",
       "\n",
       "@cuda.jit\n",
       "def add(x_array, y_array, output_array):\n",
       "        start = cuda.grid(1)\n",
       "        stride = cuda.gridsize(1)\n",
       "        for i in range(start, x.shape[0], stride):\n",
       "                output_array[i] = x_array[i] + y_array[i]\n",
       "\n",
       "a = cupy.arange(10)\n",
       "b = a * 2\n",
       "out = cupy.zeros_like(a)\n",
       "\n",
       "add[1, 32](a, b, out)\n",
       "\n",
       "print(out)  # => [ 0  3  6  9 12 15 18 21 24 27]\n",
       "```\n"
      ]
     },
     {
      "cell_type": "markdown",
      "id": "56e753a7-17e9-49b7-b32b-8ea84fcdcbc8",
      "metadata": {},
      "source": [
       "## 有用的参考链接\n",
       "Numba用于CUDA GPU：https://numba.pydata.org/numba-doc/latest/cuda/index.html \n",
       "\n",
       "CuPy的互操作性指南(包括Numba)：https://docs.cupy.dev/en/stable/user_guide/interoperability.html \n",
       "\n",
       "Numba Github仓库：https://github.com/numba/numba \n"
      ]
     },
     {
      "cell_type": "markdown",
      "id": "9b90e798-1097-432c-8464-df20bcd44ca2",
      "metadata": {},
      "source": [
       "# 示例："
      ]
     },
     {
      "cell_type": "markdown",
      "id": "4e7f01c8-7a37-459e-96b3-8d8c6fef7b40",
      "metadata": {},
      "source": [
       "## 定义和启动内核函数"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "id": "7ee68a00-ed02-46b9-be8d-33f44cd0dedf",
      "metadata": {},
      "outputs": [],
      "source": [
       "import numpy as np\n",
       "from numba import cuda\n",
       "\n",
       "input = np.asarray(range(10))\n",
       "output = np.zeros(len(input))\n",
       "\n",
       "@cuda.jit\n",
       "def foo(input_array, output_array):\n",
       "    # 1D块中的线程ID\n",
       "    thread_id = cuda.threadIdx.x\n",
       "    # 1D网格中的块ID\n",
       "    block_id = cuda.blockIdx.x\n",
       "    # 块宽度,即每个块的线程数\n",
       "    block_width = cuda.blockDim.x\n",
       "    # 计算数组内的扁平化索引\n",
       "    i = thread_id + block_id * block_width\n",
       "    if i < an_array.size:  # 检查数组边界\n",
       "        output_array[i] = input_array[i]\n",
       "\n",
       "block_threads = 32\n",
       "grid_blocks = (input.size + (block_threads - 1)) // block_threads\n",
       "\n",
       "foo[grid_blocks, block_threads](input, output)\n",
       "\n",
       "output"
      ]
     },
     {
      "cell_type": "markdown",
      "id": "869fdb03-8c5a-4ace-a92c-0a3e9b8e5a2d",
      "metadata": {},
      "source": [
       "## 使用grid()简化内核函数"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "id": "2b04229f-cf77-431b-a194-d9b591aac1b4",
      "metadata": {},
      "outputs": [],
      "source": [
       "import numpy as np\n",
       "from numba import cuda\n",
       "\n",
       "input = np.asarray(range(10))\n",
       "output = np.zeros(len(input))\n",
       "\n",
       "@cuda.jit\n",
       "def foo(input_array, output_array):\n",
       "    i = cuda.grid(1)\n",
       "    output_array[i] = input_array[i]\n",
       "    \n",
       "foo[1, len(input)](input, output)\n",
       "\n",
       "output"
      ]
     },
     {
      "cell_type": "markdown",
      "id": "546ecfb6-d788-4706-b0f7-97ce7dd7d14d",
      "metadata": {},
      "source": [
       "## 将Numba与CuPy一起使用"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "id": "1c4242a8-ac95-4c7a-b9e6-ce1dff726519",
      "metadata": {},
      "outputs": [],
      "source": [
       "import cupy\n",
       "from numba import cuda\n",
       "\n",
       "@cuda.jit\n",
       "def add(x_array, y_array, output_array):\n",
       "        start = cuda.grid(1)\n",
       "        stride = cuda.gridsize(1)\n",
       "        for i in range(start, x.shape[0], stride):\n",
       "                output_array[i] = x_array[i] + y_array[i]\n",
       "\n",
       "a = cupy.arange(10)\n",
       "b = a * 2\n",
       "out = cupy.zeros_like(a)\n",
       "\n",
       "add[1, 32](a, b, out)\n",
       "\n",
       "print(out)  # => [ 0  3  6  9 12 15 18 21 24 27]"
      ]
     }
    ],
    "metadata": {
     "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
     },
     "language_info": {
      "codemirror_mode": {
       "name": "ipython",
       "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
     }
    },
    "nbformat": 4,
    "nbformat_minor": 5
   }