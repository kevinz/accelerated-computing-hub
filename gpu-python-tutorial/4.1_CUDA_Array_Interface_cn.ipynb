{
    "cells": [
     {
      "cell_type": "markdown",
      "id": "65312eb9-ddbc-4c05-9857-1ac431bd8e66",
      "metadata": {},
      "source": [
       "# CUDA 数组接口\n",
       "\n",
       "由于将数据从 CPU 移动到 GPU 的成本很高，我们希望始终在 GPU 上保持尽可能多的数据。\n",
       "\n",
       "有时在我们的工作流程中，我们也想要更换使用的工具。比如我们用 `cupy` 加载了一个数据数组，但我们想用 `numba` 编写自定义的 CUDA 内核。或者我们想切换到使用像 `pytorch` 这样的深度学习框架。\n",
       "\n",
       "当这些库中的任何一个将数据加载到 GPU 上时，内存中的数组基本上是相同的。cupy 的 `ndarray` 和 numba 的 `DeviceNDArray` 之间的区别仅仅在于该数组如何被包装并连接到 Python。\n",
       "\n",
       "幸运的是，通过像 [DLPack](https://github.com/dmlc/dlpack) 和 [`__cuda_array__interface__`](https://numba.readthedocs.io/en/stable/cuda/cuda_array_interface.html) 这样的工具，我们可以在不修改 GPU 上的数据的情况下从一种类型转换为另一种类型。我们只需创建一个新的 Python 包装器对象并传输所有设备指针。\n",
       "\n",
       "确保流行的 GPU Python 库之间的兼容性是 RAPIDS 社区的核心目标之一。\n",
       "\n",
       "![](images/array-interface.png)"
      ]
     },
     {
      "cell_type": "markdown",
      "id": "a072fd72-44bd-4371-95b6-e853da8d7cb6",
      "metadata": {},
      "source": [
       "让我们看看这个实际操作！"
      ]
     },
     {
      "cell_type": "markdown",
      "id": "e991c2ac-4cbd-4e3c-9b1e-22f8338876dc",
      "metadata": {},
      "source": [
       "我们首先用 CuPy 创建一个数组。"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "id": "3a9dbc32-409c-45bd-8d4d-a5662030ec87",
      "metadata": {
       "tags": []
      },
      "outputs": [],
      "source": [
       "import cupy as cp\n",
       "cp_arr = cp.random.random((1, 100_000, 10_000))\n",
       "cp_arr"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "id": "0f132109-0042-417e-8b21-7ad73cc3aa52",
      "metadata": {},
      "outputs": [],
      "source": [
       "type(cp_arr)"
      ]
     },
     {
      "cell_type": "markdown",
      "id": "be2de53d-0d7f-4b3b-9859-f08520ed8bb7",
      "metadata": {},
      "source": [
       "现在让我们将其转换为 Numba 数组。"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "id": "191859ce-56c1-480f-ad6c-d76051c08c53",
      "metadata": {},
      "outputs": [],
      "source": [
       "from numba import cuda\n",
       "numba_arr = cuda.to_device(cp_arr)\n",
       "numba_arr"
      ]
     },
     {
      "cell_type": "markdown",
      "id": "18613c12-d419-4bc5-9bf0-15c07818e536",
      "metadata": {},
      "source": [
       "_注意 GPU 内存使用量保持不变。这是因为 `cp_arr` 和 `numba_arr` 引用相同的底层数据数组，但类型不同。_\n",
       "\n",
       "我们还可以将数组转换为 PyTorch 的 `Tensor` 对象。"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "id": "37dd98ce-1ff2-4fde-bd62-865d6a042a54",
      "metadata": {},
      "outputs": [],
      "source": [
       "import torch  # 需要安装 pytorch"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "id": "04d891c3-7499-4a37-a064-bf6f73c174ff",
      "metadata": {},
      "outputs": [],
      "source": [
       "torch_arr = torch.as_tensor(numba_arr, device='cuda')\n",
       "torch_arr"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "id": "4fc1495d-04c1-4746-9242-a05795586ecc",
      "metadata": {},
      "outputs": [],
      "source": [
       "type(torch_arr)"
      ]
     }
    ],
    "metadata": {
     "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
     },
     "language_info": {
      "codemirror_mode": {
       "name": "ipython",
       "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
     }
    },
    "nbformat": 4,
    "nbformat_minor": 5
   }